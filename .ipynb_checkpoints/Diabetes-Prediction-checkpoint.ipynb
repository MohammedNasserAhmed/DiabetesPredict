{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42efc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb -qqq\n",
    "\n",
    "#https://colab.research.google.com/drive/1aEv8Haa3ppfClcCiC2TB8WLHB4jnY_Ds#scrollTo=Fz-aJp3q3T4r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863a54f",
   "metadata": {},
   "source": [
    "<img src=\"results.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ee465",
   "metadata": {},
   "source": [
    "# {1} Data and Objective Description \n",
    "\n",
    "##### INPUTS\n",
    "Pregnancies              : Number of times pregnant\n",
    "\n",
    "Glucose                  : Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "\n",
    "BloodPressure            : Diastolic blood pressure (mm Hg)\n",
    "\n",
    "SkinThickness            : Triceps skin fold thickness (mm)\n",
    "\n",
    "Insulin                  : 2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "BMI                      : Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "DiabetesPedigreeFunction : Diabetes pedigree functionr\n",
    "\n",
    "Age                      : Age (years)\n",
    "\n",
    "Cabin                    : Cabin Number\n",
    "\n",
    "##### OUTPUT\n",
    "Outcome                  : Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c349d262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                   Evaluation of Accuracy                                                  |\n",
      "+--------------+-----------------------------------------------------------------------------+------------------------------+\n",
      "|   Measure    |                                  Definition                                 |           Formula            |\n",
      "+--------------+-----------------------------------------------------------------------------+------------------------------+\n",
      "| Accuracy(A)  |      Determines the accuracy of the algorithm in predicting instances.      | A=(TP+TN)/(Total of samples) |\n",
      "| Precision(P) |          Classifier correctness/accuracy is measured by Precision.          |         P=TP/(TP+FP)         |\n",
      "|  Recall(R)   |            To measure the classifier completeness or sensitivity.           |         R=TP/(TP+FN)         |\n",
      "|  F-Measure   |          F-Measure is the weighted average of precision and recall.         |       F=2*(P*R)/(P+R)        |\n",
      "|     ROC      | (Receiver Operating Curve) curves r used to compare the usefulness of tests |         P=TP/(TP+FP)         |\n",
      "+--------------+-----------------------------------------------------------------------------+------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable \n",
    "\n",
    "Measures = PrettyTable([\"Measure\", \"Definition\", \"Formula\"]) \n",
    "\n",
    "Measures.add_row([\"Accuracy(A)\", \"Determines the accuracy of the algorithm in predicting instances.\", \n",
    "                 \"A=(TP+TN)/(Total of samples)\"]) \n",
    "Measures.add_row([\"Precision(P)\", \"Classifier correctness/accuracy is measured by Precision.\", \n",
    "                 \"P=TP/(TP+FP)\"]) \n",
    "Measures.add_row([\"Recall(R)\", \"To measure the classifier completeness or sensitivity.\", \n",
    "                 \"R=TP/(TP+FN)\"]) \n",
    "Measures.add_row([\"F-Measure\", \"F-Measure is the weighted average of precision and recall.\", \n",
    "                 \"F=2*(P*R)/(P+R)\"]) \n",
    "Measures.add_row([\"ROC\", \"(Receiver Operating Curve) curves r used to compare the usefulness of tests\", \n",
    "                 \"P=TP/(TP+FP)\"]) \n",
    "\n",
    "print(Measures.get_string(title=\"Evaluation of Accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de454ff2",
   "metadata": {},
   "source": [
    "# {1}  Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e539c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb \n",
    "#wandb.login()\n",
    "#=====================================================\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer, FunctionTransformer, MinMaxScaler, PowerTransformer, LabelEncoder\n",
    "import plotly.graph_objs as go\n",
    "import dataframe_image as dfmg\n",
    "sns.set()\n",
    "from termcolor import colored\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import math\n",
    "import missingno as msno\n",
    "import plotly.offline as py\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import pandas_profiling as pp\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tabulate import tabulate\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "py.init_notebook_mode(connected=True)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import altair as alt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss, classification_report, confusion_matrix, roc_curve, auc\n",
    "from mlxtend.plotting import plot_confusion_matrix \n",
    "from sklearn.feature_selection import RFE\n",
    "import plotly.express as px\n",
    "from sklearn import model_selection\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from decimal import Decimal\n",
    "import matplotlib.patches as patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36619cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes_first = wandb.util.generate_id()\n",
    "#wandb.init(project=\"Diabetes-Predict\", group=diabetes_first)\n",
    "#wandb.log({\"f1\": f1})\n",
    "#wandb.log({\"confusion_matrix\": wandb.Image(fig)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a767aa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type = \"text/css\">\n",
       "table.dataframe td {border: 1px white solid ! important;\n",
       "                                       color: white ! important;\n",
       "                                       text-align: center;\n",
       "                                       background-color:#454140;}\n",
       "table.dataframe th{border: 3px white solid ! important;\n",
       "                   text-align: center ! important;\n",
       "                   background-color:#e0e2e4;}\n",
       "                    \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type = \"text/css\">\n",
    "table.dataframe td {border: 1px white solid ! important;\n",
    "                                       color: white ! important;\n",
    "                                       text-align: center;\n",
    "                                       background-color:#454140;}\n",
    "table.dataframe th{border: 3px white solid ! important;\n",
    "                   text-align: center ! important;\n",
    "                   background-color:#e0e2e4;}\n",
    "                    \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34dcbb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# color palette for visualizations\n",
    "colors = ['#454140','#c1502e','#a79e84','#7a3b2e','#e0e2e4']\n",
    "palette = sns.color_palette( palette = colors)\n",
    "\n",
    "sns.palplot(palette, size =2.5)\n",
    "plt.text(0.5,-0.55,'Color map for Visualization', {'font':'Rockwell', 'size':25, 'weight':'bold', 'color':'Grey'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5baf3",
   "metadata": {},
   "source": [
    "# {2}  Collect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8190fcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "5            5      116             74              0        0  25.6   \n",
       "6            3       78             50             32       88  31.0   \n",
       "7           10      115              0              0        0  35.3   \n",
       "8            2      197             70             45      543  30.5   \n",
       "9            8      125             96              0        0   0.0   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  \n",
       "5                     0.201   30        0  \n",
       "6                     0.248   26        1  \n",
       "7                     0.134   29        0  \n",
       "8                     0.158   53        1  \n",
       "9                     0.232   54        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "Diab = diabetes[(diabetes['Outcome'] != 0)]\n",
    "Non_Diab = diabetes[(diabetes['Outcome'] == 0)]\n",
    "diabetes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267ea23",
   "metadata": {},
   "source": [
    "By taking a look at the head observtions :\n",
    "\n",
    "- Data has only float and integer values.\n",
    "\n",
    "- No variable column has null/missing values.\n",
    "\n",
    "But some variables have minimum = 0 which is not making sense. So let us explore these variables and treat them accordingly . .\n",
    "On these columns :\n",
    "\n",
    "- Glucose\n",
    "- BloodPressure\n",
    "- SkinThickness\n",
    "- Insulin\n",
    "- BMI\n",
    "\n",
    "A value of zero does not make sense and indicates missing value,\n",
    "and that will being considered when reloading dataset as below !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d881e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DPF</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI    DPF  \\\n",
       "0            6    148.0           72.0           35.0      NaN  33.6  0.627   \n",
       "1            1     85.0           66.0           29.0      NaN  26.6  0.351   \n",
       "2            8    183.0           64.0            NaN      NaN  23.3  0.672   \n",
       "3            1     89.0           66.0           23.0     94.0  28.1  0.167   \n",
       "4            0    137.0           40.0           35.0    168.0  43.1  2.288   \n",
       "\n",
       "   Age  Outcome  \n",
       "0   50        1  \n",
       "1   31        0  \n",
       "2   32        1  \n",
       "3   21        0  \n",
       "4   33        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the dataset by assigning NaN vale to 0's Values in the intended variables\n",
    "ds = pd.read_csv('diabetes.csv', na_values = {'Glucose':0,\n",
    "                                    'BloodPressure':0,\n",
    "                                    'SkinThickness':0,\n",
    "                                    'Insulin':0,\n",
    "                                    'BMI':0})\n",
    "# Replace DiabetesPedigreeFunction column to DPF for visualization purpose only\n",
    "ds.rename(columns={'DiabetesPedigreeFunction': 'DPF'}, inplace=True)\n",
    "\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2b82c",
   "metadata": {},
   "source": [
    "The dataset has been loaded as a dataframe using pd.read_csv() function and displays the first 5 rows of the dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f1b1c",
   "metadata": {},
   "source": [
    "# {3} Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7deda0",
   "metadata": {},
   "source": [
    "## The major topics to be covered are below:\n",
    "\n",
    "– Handle Missing value\n",
    "\n",
    "– Removing duplicates\n",
    "\n",
    "– Outlier Treatment\n",
    "\n",
    "– Normalizing and Scaling( Numerical Variables)\n",
    "\n",
    "– Encoding Categorical variables( Dummy Variables)\n",
    "\n",
    "– Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4677c59c",
   "metadata": {},
   "source": [
    "## [3 : 1]  Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57bc202c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============|\u001b[34m The dataset information \u001b[0m |===========\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Pregnancies    768 non-null    int64  \n",
      " 1   Glucose        763 non-null    float64\n",
      " 2   BloodPressure  733 non-null    float64\n",
      " 3   SkinThickness  541 non-null    float64\n",
      " 4   Insulin        394 non-null    float64\n",
      " 5   BMI            757 non-null    float64\n",
      " 6   DPF            768 non-null    float64\n",
      " 7   Age            768 non-null    int64  \n",
      " 8   Outcome        768 non-null    int64  \n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 54.1 KB\n",
      "\n",
      "============|\u001b[34m The 5th head observations\u001b[0m |===========\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DPF</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI    DPF  \\\n",
       "0            6    148.0           72.0           35.0      NaN  33.6  0.627   \n",
       "1            1     85.0           66.0           29.0      NaN  26.6  0.351   \n",
       "2            8    183.0           64.0            NaN      NaN  23.3  0.672   \n",
       "3            1     89.0           66.0           23.0     94.0  28.1  0.167   \n",
       "4            0    137.0           40.0           35.0    168.0  43.1  2.288   \n",
       "\n",
       "   Age  Outcome  \n",
       "0   50        1  \n",
       "1   31        0  \n",
       "2   32        1  \n",
       "3   21        0  \n",
       "4   33        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('============|'+colored(' The dataset information ','blue')+' |===========\\n')\n",
    "ds.info()\n",
    "print('\\n============|'+colored(' The 5th head observations','blue')+' |===========\\n')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5f2f9",
   "metadata": {},
   "source": [
    "From the above details, we can observe characteristics such as :\n",
    "\n",
    "    - how many rows and columns are in the dataset\n",
    "    \n",
    "    - what are the data types of the features\n",
    "    \n",
    "    - how many categorical and numerical features are within the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890eea2",
   "metadata": {},
   "source": [
    " NOTE : Looking at the data above, it s seems, we only have numeric values, we don’t need to do any data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "227d4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================| \u001b[34m DTypes \u001b[0m |========================\n",
      "\n",
      "Pregnancies        int64\n",
      "Glucose          float64\n",
      "BloodPressure    float64\n",
      "SkinThickness    float64\n",
      "Insulin          float64\n",
      "BMI              float64\n",
      "DPF              float64\n",
      "Age                int64\n",
      "Outcome            int64\n",
      "\n",
      "===============| \u001b[34mCounts of DTypes \u001b[0m |=================\n",
      "\n",
      "float64    6\n",
      "int64      3\n",
      "\n",
      "\n",
      "===============| \u001b[34mRows and Columns\u001b[0m |=================\n",
      "\n",
      "(768, 9)\n",
      "\n",
      "\n",
      "================|\u001b[34mColumns Names\u001b[0m |===================\n",
      "\n",
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DPF', 'Age', 'Outcome']\n",
      "\n",
      "\n",
      "================| \u001b[34mNulls per Column\u001b[0m |================\n",
      "\n",
      "Pregnancies        0\n",
      "Glucose            5\n",
      "BloodPressure     35\n",
      "SkinThickness    227\n",
      "Insulin          374\n",
      "BMI               11\n",
      "DPF                0\n",
      "Age                0\n",
      "Outcome            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "=========| \u001b[34mPrecentage of Nulls per Column\u001b[0m |=========\n",
      "\n",
      "Pregnancies      0.000\n",
      "Glucose          0.007\n",
      "BloodPressure    0.046\n",
      "SkinThickness    0.296\n",
      "Insulin          0.487\n",
      "BMI              0.014\n",
      "DPF              0.000\n",
      "Age              0.000\n",
      "Outcome          0.000\n"
     ]
    }
   ],
   "source": [
    "def shot_analysis(df):\n",
    "    print(\"======================| \"+colored(' DTypes ','blue')+\" |========================\\n\")\n",
    "    print(\"\"+str(df.dtypes.to_string())+\"\\n\\n===============| \"+colored('Counts of DTypes ','blue')+\" |=================\\n\\n\"+str(df.dtypes.value_counts().to_string())+\"\")\n",
    "    print(\"\\n\\n===============| \"+colored('Rows and Columns','blue')+\" |=================\\n\")\n",
    "    print(df.shape)\n",
    "    print(\"\\n\\n================|\"+colored('Columns Names','blue')+\" |===================\\n\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\n\\n================| \"+colored('Nulls per Column','blue')+\" |================\\n\")\n",
    "    print(df.apply(lambda x: sum(x.isnull())))\n",
    "    print(\"\\n\\n=========| \"+colored('Precentage of Nulls per Column','blue')+\" |=========\\n\")\n",
    "    print(df.apply(lambda x: Decimal(sum(x.isnull()) / len(df)).quantize(Decimal('0.001'))).to_string())\n",
    "shot_analysis(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751c99be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================|\u001b[34m The describtion of dataset \u001b[0m |====================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DPF</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.00</td>\n",
       "      <td>763.00</td>\n",
       "      <td>733.00</td>\n",
       "      <td>541.00</td>\n",
       "      <td>394.00</td>\n",
       "      <td>757.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.85</td>\n",
       "      <td>121.69</td>\n",
       "      <td>72.41</td>\n",
       "      <td>29.15</td>\n",
       "      <td>155.55</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>33.24</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.37</td>\n",
       "      <td>30.54</td>\n",
       "      <td>12.38</td>\n",
       "      <td>10.48</td>\n",
       "      <td>118.78</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.76</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>76.25</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>117.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>32.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>141.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>36.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>122.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>846.00</td>\n",
       "      <td>67.10</td>\n",
       "      <td>2.42</td>\n",
       "      <td>81.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  \\\n",
       "count       768.00   763.00         733.00         541.00   394.00 757.00   \n",
       "mean          3.85   121.69          72.41          29.15   155.55  32.46   \n",
       "std           3.37    30.54          12.38          10.48   118.78   6.92   \n",
       "min           0.00    44.00          24.00           7.00    14.00  18.20   \n",
       "25%           1.00    99.00          64.00          22.00    76.25  27.50   \n",
       "50%           3.00   117.00          72.00          29.00   125.00  32.30   \n",
       "75%           6.00   141.00          80.00          36.00   190.00  36.60   \n",
       "max          17.00   199.00         122.00          99.00   846.00  67.10   \n",
       "\n",
       "         DPF    Age  Outcome  \n",
       "count 768.00 768.00   768.00  \n",
       "mean    0.47  33.24     0.35  \n",
       "std     0.33  11.76     0.48  \n",
       "min     0.08  21.00     0.00  \n",
       "25%     0.24  24.00     0.00  \n",
       "50%     0.37  29.00     0.00  \n",
       "75%     0.63  41.00     1.00  \n",
       "max     2.42  81.00     1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "print('\\n===================|'+colored(' The describtion of dataset ','blue')+' |====================\\n')\n",
    "display(ds.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc0e873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================|\u001b[34m The measures of Central Tendency \u001b[0m |====================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DPF</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.85</td>\n",
       "      <td>121.69</td>\n",
       "      <td>72.41</td>\n",
       "      <td>29.15</td>\n",
       "      <td>155.55</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>33.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>3.00</td>\n",
       "      <td>117.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>32.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "mean           3.85   121.69          72.41          29.15   155.55 32.46   \n",
       "median         3.00   117.00          72.00          29.00   125.00 32.30   \n",
       "mode           1.00    99.00          70.00          32.00   105.00 32.00   \n",
       "\n",
       "        DPF   Age  \n",
       "mean   0.47 33.24  \n",
       "median 0.37 29.00  \n",
       "mode   0.26 22.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Measures of Central Tendency\n",
    "print('\\n===================|'+colored(' The measures of Central Tendency ','blue')+' |====================\\n')\n",
    "ds.drop('Outcome', axis=1).aggregate([np.mean, np.median, lambda x:x.value_counts().index[0]]).rename(index={'<lambda>': 'mode'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badaac3d",
   "metadata": {},
   "source": [
    "Here as you can notice mean value is less than median value of each column which is represented by 50th percentile (50%) in index column, and there is notably a large difference between 75th % and max values of predictors “pregnancies”,”SkinThickness”,”Insulin”,\"BMI\",\"DPF\" and \"Age\".\n",
    "\n",
    "Thus observations suggests that there are extreme values-Outliers in our dataset !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0326a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================|\u001b[34m The measures of Dispersion \u001b[0m |====================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.37</td>\n",
       "      <td>31.97</td>\n",
       "      <td>19.36</td>\n",
       "      <td>15.95</td>\n",
       "      <td>115.24</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>11.35</td>\n",
       "      <td>1022.25</td>\n",
       "      <td>374.65</td>\n",
       "      <td>254.47</td>\n",
       "      <td>13281.18</td>\n",
       "      <td>62.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>138.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IQR</th>\n",
       "      <td>5.00</td>\n",
       "      <td>41.25</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>127.25</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.27</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "std              3.37    31.97          19.36          15.95   115.24  7.88   \n",
       "variance        11.35  1022.25         374.65         254.47 13281.18 62.16   \n",
       "IQR              5.00    41.25          18.00          32.00   127.25  9.30   \n",
       "skewness         0.90     0.17          -1.84           0.11     2.27 -0.43   \n",
       "\n",
       "          DiabetesPedigreeFunction    Age  \n",
       "std                           0.33  11.76  \n",
       "variance                      0.11 138.30  \n",
       "IQR                           0.38  17.00  \n",
       "skewness                      1.92   1.13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Measures of Dispersion\n",
    "print('\\n===================|'+colored(' The measures of Dispersion ','blue')+' |====================\\n')\n",
    "diabetes.drop('Outcome', axis=1).apply(lambda x: pd.Series({'std': x.std(), 'variance': x.var(),\n",
    "                                                                'IQR' : stats.iqr(x), 'skewness' : x.skew()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9900f",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89d1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = pp.ProfileReport(ds, title='Diabetes Profiling Report')\n",
    "#profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a60af",
   "metadata": {},
   "source": [
    "## [3 : 2] Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae16b23",
   "metadata": {},
   "source": [
    "There are several factors to consider in the data cleaning process : \n",
    "\n",
    "- Duplicate or irrelevant inputs.\n",
    "\n",
    "- Bad labeling of data or same category occurring multiple times.\n",
    "\n",
    "- Missing or Null data points.\n",
    "\n",
    "- Unexpected outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a64b5b",
   "metadata": {},
   "source": [
    "### [3 : 2 : 1] Inconsistent data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd348055",
   "metadata": {},
   "source": [
    " - By looking at the previous step (explore the data) you can confirm that no irrelevant inputs, bad labelling or categories repeated\n",
    " - We already know that no feature must be unique, so we can check dulicates based on all columns as following :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6785c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGREAT NEWS : No dublictaes or inconsistent data found in the dataset !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duplicateRowsDs = ds[ds.duplicated()]\n",
    "if duplicateRowsDs.empty:\n",
    "    print(colored('GREAT NEWS : No dublictaes or inconsistent data found in the dataset !','blue'))\n",
    "else:\n",
    "    print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
    "    print(duplicateRowsDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d2b95",
   "metadata": {},
   "source": [
    "### [3 : 2 : 2] Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8118bd0",
   "metadata": {},
   "source": [
    "#### [3 : 2 : 2 : 1] Explore the MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b49a356",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_6832/221442197.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\MohdNass\\AppData\\Local\\Temp/ipykernel_6832/221442197.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print('=============| '+ colored ('The total precentage of Missing Data','blue') '|============== \\n\\n'+str(round(len(ds.iloc[ds[(ds.isnull().sum(axis=1) >= 1)].index]) * 100 / len(ds),1))+' %'\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Check which variables have missing values\n",
    "columns_with_missing_values = ds.columns[ds.isnull().any()]\n",
    "print('=============|'+ colored ('The columns and counts of missing values','blue')+ '|============== \\n\\n'+str(ds[columns_with_missing_values].isnull().sum().to_string())+'')\n",
    "print('=============| '+ colored ('The total precentage of Missing Data','blue') '|============== \\n\\n'+str(round(len(ds.iloc[ds[(ds.isnull().sum(axis=1) >= 1)].index]) * 100 / len(ds),1))+' %'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "        mis_val = data.isnull().sum()\n",
    "        mis_val_percent = 100 * data.isnull().sum() / len(data)\n",
    "        m_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        m_table = m_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        m_table['Data Type'] = data.dtypes\n",
    "        m_table = m_table[m_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "        print (\"=============| MISSING VALUES ( Columns, Counts, Precentage & Data Types) |==============\\n\\n\",\"\\nThere are \" + str(m_table.shape[0]) + \" columns that have missing values :\")\n",
    "        return m_table\n",
    "    \n",
    "tb = pd.DataFrame(missing_values(ds))\n",
    "tb    \n",
    "#print('\\n',str(tabulate(missing_values(ds),headers=['Feature','MissingValues','% of TotalValues','DataType'], tablefmt='psql')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff871d6",
   "metadata": {},
   "source": [
    "#### [3 : 2 : 2 : 2] Visualize the  Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac9857",
   "metadata": {},
   "source": [
    "#####  Matplot Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To hold variable names\n",
    "labels = [] \n",
    "# To hold the count of missing values for each variable \n",
    "valuecount = [] \n",
    "# To hold the percentage of missing values for each variable\n",
    "percentcount = [] \n",
    "for col in columns_with_missing_values:\n",
    "    labels.append(col)\n",
    "    valuecount.append(ds[col].isnull().sum())\n",
    "    percentcount.append(ds[col].isnull().sum()/ds.shape[0])\n",
    "\n",
    "ind = np.arange(len(labels))\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,8))\n",
    "rects = ax1.barh(ind, np.array(valuecount), color='#7a3b2e')\n",
    "ax1.set_yticks(ind)\n",
    "ax1.set_yticklabels(labels, rotation='horizontal',weight='bold')\n",
    "ax1.set_xlabel(\"Count of missing values\", labelpad=20, weight='bold', size=14)\n",
    "ax1.set_title(\"Variables with missing values\", weight='bold', size=15)\n",
    "# Draw vertical axis lines\n",
    "vals = ax1.get_xticks()\n",
    "for tick in vals:\n",
    "      ax1.axvline(x=tick, linestyle='dashed', alpha=0.3, color='white', zorder=1)\n",
    "for i, v in enumerate(valuecount):\n",
    "    ax1.text(v+10 , i, str( v), color='red', fontweight='bold', size=13)\n",
    "rects = ax2.barh(ind, np.array(percentcount), color='#a79e84')\n",
    "ax2.set_yticks(ind)\n",
    "ax2.set_yticklabels(labels, rotation='horizontal', weight='bold')\n",
    "ax2.set_xlabel(\"Percentage of missing values\", labelpad=20, weight='bold', size=14)\n",
    "ax2.set_title(\"Variables with missing values\", weight='bold', size=15)\n",
    "vals = ax2.get_xticks()\n",
    "for tick in vals:\n",
    "      ax2.axvline(x=tick, linestyle='dashed', alpha=0.3, color='white', zorder=1)\n",
    "for i, v in enumerate(percentcount):\n",
    "    ax2.text(v, i, \"{: .1%}\".format(v), color='red', fontweight='bold', size=13)\n",
    "fig.show()\n",
    "#wandb.log({\"MissingData-Count-Precentage\": wandb.Image(fig)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0fd7d",
   "metadata": {},
   "source": [
    "##### MSNO Matrix OR SNS Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2157875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "cmap = sns.cubehelix_palette(light=1,rot=-.4,as_cmap=True, start=2.8, reverse=True)\n",
    "sns.heatmap(ds.isnull(), cmap='rocket')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87e760",
   "metadata": {},
   "source": [
    "##### MSNO Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018502a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(ds, cmap='vlag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742c46d",
   "metadata": {},
   "source": [
    "##### MSNO Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['grey','#c1502e']*4\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,5), dpi = 70)\n",
    "fig.patch.set_facecolor('#e0e2e4')\n",
    "ax.set_facecolor('#e0e2e4')\n",
    "\n",
    "\n",
    "msno.bar(ds, sort = 'descending', \n",
    "         color = color, \n",
    "         ax = ax, fontsize =13,\n",
    "         labels = 'off',filter = 'top')\n",
    "\n",
    "ax.text(1,1.35,'Visualizing Null Values in Diabetes dataset',{'font': 'Cooper Black', 'Size': 24, 'color':'#c1502e'},alpha = 0.9)\n",
    "ax.text(-0.5,1.2,'As the barchart suggest, there are Null Values in : ' + '[%s]' % ', '.join(map(str, ds.columns[ds.isna().any()].tolist()))+\"\",{'font': 'Segoe Marker', 'Size': 18, 'color':'Black'}, alpha = 0.7)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90, \n",
    "                   ha = 'center', **{'font': 'Rockwell', 'Size': 13,'weight':'normal','color':'#512b58'}, alpha = 1)\n",
    "ax.set_yticklabels('')\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "fig.show()\n",
    "#wandb.log({\"Null-Values Viz\": wandb.Image(fig)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c00f2",
   "metadata": {},
   "source": [
    "#### [3 : 2 : 2 : 3] Fix the Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d2ddb",
   "metadata": {},
   "source": [
    "It is important that we find and handle these missing values properly, as it could affect the accuracy of the model prediction. There are several ways of handling missing values, these includes:\n",
    "\n",
    "1) Dropping the missing values completely.\n",
    "\n",
    "2) Replacing missing values with the mean, mode or median.\n",
    "\n",
    "3) Filling the missing values by interpolation\n",
    "\n",
    "In our case, we would be replacing the missing values with the MEDIAN  This is because  that the percentage of null values in the dataset is approximatly 50 %  and we do not want to loose any important data by dropping missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b332af",
   "metadata": {},
   "source": [
    "##### Replacing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250a663",
   "metadata": {},
   "source": [
    "We have two parts of the variables with missing values :\n",
    "\n",
    "       1- Missing values less than 25 %\n",
    "       \n",
    "       2- Missing values greater than 25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b33bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"=============| The variables with missing values less than 25 %  |=============== \\n\\n {tb.index[tb['% of Total Values'] < 25].tolist()} \\n\\n\")\n",
    "print(f\"=============| The variables with missing values greater than 25 %  |=============== \\n\\n {tb.index[tb['% of Total Values'] >= 25].tolist()} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the missing values of a variable by Outcome \n",
    "def print_var_miss(col):\n",
    "    print(f\"Total Missing Values in  {col}  feature : \", ds[ds[col].isna()].shape[0])\n",
    "    print('\\n\\n',str(tabulate(ds[ds[col].isna()].groupby('Outcome')['Age'].count().reset_index(),headers=['Outcome','No. of '+str(col)+' NULLs'], tablefmt='psql',showindex=False)))\n",
    "\n",
    "def plot_distribution(df, col, bins) :  \n",
    "    dt1 = df[df['Outcome'] != 0][col]\n",
    "    dt2 = df[df['Outcome'] == 0][col]\n",
    "    data = [dt1, dt2]\n",
    "    group_labels = ['Positive', 'Negative']\n",
    "    color = ['#c1502e','#a79e84','#7a3b2e','#e0e2e4']\n",
    "    fig = ff.create_distplot(data, group_labels, colors = color, show_hist = True, bin_size = bins, curve_type='kde') \n",
    "    fig['layout'].update(title = col)\n",
    "    py.iplot(fig, filename = 'Density plot')\n",
    "\n",
    "# Filling missing values less than 25% with Median\n",
    "def fill_missing_with_median(col):   \n",
    "    data = ds[ds[col].notnull()] \n",
    "    data = data[[col, 'Outcome']].groupby(['Outcome'])[col].median().reset_index()\n",
    "    ds.loc[(ds['Outcome'] == 0 ) & (ds[col].isnull()), col] = round(data[col][0],2)\n",
    "    ds.loc[(ds['Outcome'] == 1 ) & (ds[col].isnull()), col] = round(data[col][1],2)\n",
    "    print('ALL missing values of '+str(col)+' have been filled with median, the inputs with Outcome = 0 being filled with median = '\n",
    "          +str(data[col][0])+' and inputs with Outcome = 1 being filled with median = '+str(data[col][1])+'')\n",
    "    \n",
    "    \n",
    "def density_plot(col):\n",
    "    sns.set(rc={'figure.figsize':(10,5)})\n",
    "    sns.distplot(ds[col], hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'shade': True,'linewidth': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd668263",
   "metadata": {},
   "source": [
    "###### 1- Missing precentage less than 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b680c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print median and mean of all features (with missing values) by Outcome\n",
    "ds.groupby('Outcome')[['Insulin','SkinThickness','BloodPressure','BMI','Glucose']].aggregate([np.mean, np.median]).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49435c3",
   "metadata": {},
   "source": [
    "We are going to fill missing values by the median values variable by variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8df0b",
   "metadata": {},
   "source": [
    "###### -> Insulin Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing values by Outcome\n",
    "print_var_miss('Insulin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79f07e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Diatribution Insulin befor filling\n",
    "plot_distribution(diabetes,'Insulin', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1baef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with Median\n",
    "fill_missing_with_median('Insulin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution Insulin after filling\n",
    "plot_distribution(ds,'Insulin', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80550b30",
   "metadata": {},
   "source": [
    "###### -> SkinThickness Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6dd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values by Outcome\n",
    "print_var_miss('SkinThickness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0877655",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Diatribution SkinThickness befor filling\n",
    "plot_distribution(diabetes,'SkinThickness', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "fill_missing_with_median('SkinThickness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution SkinThickness after filling\n",
    "plot_distribution(ds,'SkinThickness', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ec934",
   "metadata": {},
   "source": [
    "######  -> BloodPressure Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b95fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values by Outcome\n",
    "print_var_miss('BloodPressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution BloodPressure befor filling\n",
    "plot_distribution(diabetes,'BloodPressure', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3846147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fillimg with Median\n",
    "fill_missing_with_median('BloodPressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fee86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution BloodPressure after filling\n",
    "plot_distribution(ds,'BloodPressure', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff2e8a",
   "metadata": {},
   "source": [
    "###### -> BMI Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371af2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values by Outcome\n",
    "print_var_miss('BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution BMI befor filling\n",
    "plot_distribution(diabetes,'BMI', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling with Median\n",
    "fill_missing_with_median('BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution BMI after filling\n",
    "plot_distribution(ds,'BMI', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0c975",
   "metadata": {},
   "source": [
    "###### -> Glucose Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values by Outcome\n",
    "print_var_miss('Glucose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution Glucose befor filling\n",
    "plot_distribution(diabetes,'Glucose', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling with Median\n",
    "fill_missing_with_median('Glucose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diatribution Glucose after filling\n",
    "plot_distribution(ds,'Glucose', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf1686",
   "metadata": {},
   "source": [
    "###### Check Nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee070c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NULLs again\n",
    "print(ds.isnull().sum().to_frame('Nulls'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8342c6",
   "metadata": {},
   "source": [
    "### [3 : 2 : 3] Noisy Data  (Outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e26ffc",
   "metadata": {},
   "source": [
    "###### Boxplot\n",
    "\n",
    "In descriptive statistics, a box plot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles, hence the terms box-and-whisker plot and box-and-whisker diagram. Outliers may be plotted as individual points.\n",
    "\n",
    "Above definition suggests, that if there is an outlier it will plotted as point in boxplot but other population will be grouped together and display as boxes.\n",
    "\n",
    "\n",
    "###### interquartile\n",
    "\n",
    "The interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 − Q1.\n",
    "In other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data.\n",
    "It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d6552",
   "metadata": {},
   "source": [
    "#### [3 : 2 : 3 : 1] Check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96366aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Outliers existed or not using Boxplot \n",
    "plt.subplots(figsize=(20, 15))\n",
    "i=0\n",
    "for col in ds.drop('Outcome', axis=1).columns:\n",
    "    i+=1\n",
    "    plt.subplot(3,3,i)\n",
    "    sns.boxplot(ds[col], color='#a79e84')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37455100",
   "metadata": {},
   "source": [
    "Insights : \n",
    "\n",
    "    - In our dataset except “Glucose” all other features columns shows outliers !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f9e40",
   "metadata": {},
   "source": [
    "#### [3 : 2 : 3 : 2] Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca13649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers per variable using [ Interquartile Range Method ]\n",
    "def detect_outliers_iqr(df):\n",
    "    total=0\n",
    "    for col in df.drop('Outcome', axis=1):\n",
    "        q25, q75 = np.percentile(df[col], 25), np.percentile(df[col], 75)\n",
    "        iqr = q75 - q25\n",
    "        print(f'========| Outliers in {col} |=========\\n')\n",
    "        print('Percentiles: 25th = %.3f, 75th = %.3f, IQR = %.3f' % (q25, q75, iqr))\n",
    "        # calculate the outlier cutoff\n",
    "        cut_off = iqr * 1.5\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        # identify outliers\n",
    "        outliers = [x for x in df[col] if x < lower or x > upper]\n",
    "        if len(outliers) == 0:\n",
    "            print(colored (f'Identified outliers in {col} : %d','blue') % len(outliers))\n",
    "        else:\n",
    "            print(colored (f'Identified outliers in {col} : %d','red') % len(outliers))\n",
    "        # remove outliers\n",
    "        outliers_removed = [x for x in df[col] if x >= lower and x <= upper]\n",
    "        print(colored(f'Non-outlier observations in {col} : %d \\n\\n','blue') % len(outliers_removed))\n",
    "        total=total + len(outliers)\n",
    "    print('\\033[1m'+'\\n\\nTotal outliers in the dataset'+'\\033[1m','\\033[1m'+f' : {total}'+'\\033[1m')\n",
    "    print('\\033[1m'+'\\nPrecentage of outliers in the dataset'+'\\033[1m','\\033[1m'+f' : {round(total/len(df),2)} %'+'\\033[1m')\n",
    "detect_outliers_iqr(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc470c8",
   "metadata": {},
   "source": [
    "#### [3 : 2 : 3 : 3]  Replacing / Removing Ouliers using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2980a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OUTLIERS limits\n",
    "# GET Limits (quartiles)[1]\n",
    "def limits_iqr(df, col, q1=0.25, q3=0.75):\n",
    "    quartile1 = df[col].quantile(q1)\n",
    "    quartile3 = df[col].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "# GET Limits (Gaussian (mean & std)[2]\n",
    "def limits_gaussian(df,col):\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    get_off = std * 3\n",
    "    up_limit = mean + get_off\n",
    "    low_limit = mean - get_off\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Replacing OUTLIERS using IQR and std (according to the skewed and non skewed columns)\n",
    "def check_outliers(df, col, lower, upper):\n",
    "    if df[(df[col] > upper) | (df[col] < lower)].any(axis=None):\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "def replace_with_thresholds(df,cols,replace=False):\n",
    "    data = []\n",
    "    for col in cols:\n",
    "        if col != 'Outcome':\n",
    "            count = None\n",
    "            lower_limit, upper_limit = limits_iqr(df, col)\n",
    "            outliers_ = check_outliers(df, col, lower_limit, upper_limit)\n",
    "            if lower_limit < df[col].min():\n",
    "                lower_limit = df[col].min()\n",
    "            lower_outliers = len(df[df[col] < lower_limit])\n",
    "            upper_outliers = len(df[df[col] > upper_limit])\n",
    "            if outliers_:\n",
    "                count = df[(df[col] > upper_limit) | (df[col] < lower_limit)][col].count()\n",
    "                if replace: \n",
    "                    if lower_limit < 0:\n",
    "                        # We don't want to replace with negative values, right!\n",
    "                        df.loc[(df[col] > upper_limit), col] = upper_limit\n",
    "                    else:\n",
    "                        df.loc[(df[col] < lower_limit), col] = lower_limit\n",
    "                        df.loc[(df[col] > upper_limit), col] = upper_limit\n",
    "            outliers_status = check_outliers(df, col, lower_limit, upper_limit)\n",
    "            data.append([col,outliers_, count, lower_limit, upper_limit,lower_outliers, upper_outliers, outliers_status ])\n",
    "    table = tabulate(data, headers=['Column','Outliers', 'Count', 'LowerLimit', 'UpperLimit','LowerOutliers','UpperOutliers', 'Outliers'], tablefmt='rst', numalign='left', stralign='left')\n",
    "    print(colored(\"\\n\\nReplacing Outliers using IQR : \\n\\n\",'blue'))\n",
    "    print(table)\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# Removing OUTLIERS\n",
    "def remove_outlrs(data, var, txt):\n",
    "    if txt == \"iqr\":\n",
    "        low_limit, up_limit = limits_iqr(data, var)\n",
    "    else:\n",
    "        low_limit, up_limit = limits_gaussian(data, var)\n",
    "    outliers = np.where(data[var] > up_limit, True, np.where(data[var] < low_limit, True, False))\n",
    "    # remove outliers from data.\n",
    "    data = data.loc[~(outliers), ]\n",
    "    # data = data.loc[(data[var] > low_limit) & (data[var] < up_limit)]\n",
    "    return data\n",
    "\n",
    "#===========================================================================\n",
    "\n",
    "#Distribuation and Boxploting\n",
    "def dist_box (df, col) :\n",
    "    fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(15,4))\n",
    "    sns.histplot(df[col],kde=True,ax=axes[0],color=colors[1])\n",
    "    sns.boxplot(df[col],ax=axes[1],color=colors[3])\n",
    "\n",
    "def boxplot(col):\n",
    "    f, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    sns.boxplot(x='Outcome',y=col,data=ds,ax=ax)\n",
    "    plt.xticks(ticks=[0,1],labels=['Non-Diab.','Diab.'],fontsize=10)\n",
    "    ax.set_xlabel('Category',fontdict={'fontsize':10})\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Describtive Statestics of dataset\n",
    "def statestics(df):\n",
    "    stat = df.describe().T\n",
    "    stat_df = pd.DataFrame(index= [col for col in df.columns], \n",
    "                           columns= stat.columns,\n",
    "                           data= stat)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(10,\n",
    "                                 stat_df.shape[0]*0.78))\n",
    "    sns.heatmap(stat_df,\n",
    "                annot=True,\n",
    "                cmap = colors,\n",
    "                fmt= '.2f',\n",
    "                ax=ax,\n",
    "                linewidths = 2.6,\n",
    "                cbar = False,\n",
    "                annot_kws={\"size\": 15})\n",
    "    plt.xticks(size = 18)\n",
    "    plt.yticks(size = 14,\n",
    "               rotation = 0)\n",
    "    plt.title(\"Descriptive Statistics\", size = 18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26765cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describtive Statestics befor removing Outliers\n",
    "statestics(ds.iloc[:,ds.columns !=\"Outcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3ab09",
   "metadata": {},
   "source": [
    "###### Replace Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a600bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace outliers using IQR and std\n",
    "ds_OUT_replace=ds.copy()\n",
    "replace_with_thresholds(ds_OUT_replace, ds_OUT_replace.columns, True)\n",
    "print(colored(\"\\n\\nThe dataset shape after replacing outliers : \\n\\n\",'blue'),ds_OUT_replace.shape)\n",
    "print (colored(\"\\n\\nDescribtive Statestics after replacing OUTLIERS : \",'blue'))\n",
    "statestics(ds_OUT_replace.iloc[:,ds_OUT_replace.columns !=\"Outcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbd111",
   "metadata": {},
   "source": [
    "###### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a29224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Outliers using IQR\n",
    "ds_OUT_remove=ds.copy()\n",
    "for col in ds_OUT_remove.drop('Outcome', axis=1):\n",
    "    ds_OUT_remove = remove_outlrs(ds_OUT_remove,col, 'iqr')\n",
    "\n",
    "print(colored(\"\\nThe dataset shape after removing outliers : \\n\\n\",'blue'),ds_OUT_remove.shape)\n",
    "print (colored(\"\\n\\nDescribtive Statestics after removing OUTLIERS : \",'blue'))\n",
    "statestics(ds_OUT_remove.iloc[:,ds_OUT_remove.columns !=\"Outcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455d1c3",
   "metadata": {},
   "source": [
    "## [3 : 3] Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a6dcd",
   "metadata": {},
   "source": [
    "### [3 : 3 : 1] Uni-Variate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d03f74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar and pie plots for Outcome variable\n",
    "fig = make_subplots(rows=1,cols=2,\n",
    "                        subplot_titles=('Countplot','Percentages'),\n",
    "                        specs=[[{\"type\": \"xy\"}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Bar( y = ds_OUT_remove['Outcome'].value_counts().values.tolist(), \n",
    "                          x = ds_OUT_remove['Outcome'].value_counts().index, \n",
    "                          text=ds_OUT_remove['Outcome'].value_counts().values.tolist(),\n",
    "                          textfont=dict(size=17),\n",
    "                          name = 'Outcome',\n",
    "                          textposition = 'auto',\n",
    "                          showlegend=False,\n",
    "                          marker=dict(color = colors,\n",
    "                                      line=dict(color='white',\n",
    "                                                width=1.5))),\n",
    "                  row = 1, col = 1)\n",
    "    \n",
    "fig.add_trace(go.Pie(labels=ds_OUT_remove['Outcome'].value_counts().reset_index(name='count').replace({'index' : { 0 : 'Negative', 1 : 'Positive' }})['index'].tolist(),\n",
    "                         values=ds_OUT_remove['Outcome'].value_counts().reset_index(name='count').replace({'index' : { 0 : 'Negative', 1 : 'Positive' }})['count'].tolist(),\n",
    "                         textfont = dict(size = 20),\n",
    "                         textposition='auto',\n",
    "                         showlegend = True,\n",
    "                         name = 'Outcome',\n",
    "                         marker=dict(colors=colors)),\n",
    "                  row = 1, col = 2)\n",
    "    \n",
    "fig.update_layout(title={'text': str('Outcome'),\n",
    "                             'y':0.9,\n",
    "                             'x':0.5,\n",
    "                             'xanchor': 'center',\n",
    "                             'yanchor': 'top'},\n",
    "                      template='ggplot2')\n",
    "    \n",
    "iplot(fig)\n",
    "#wandb.log({\"Outcome-Summary\": wandb.Image(fig)})\n",
    "# ==========================================================================\n",
    "\n",
    "#Precentage and count of Outcome\n",
    "df_count = pd.DataFrame(ds_OUT_remove.groupby(['Outcome']).Outcome.count())\n",
    "D=int(round((100. * ds_OUT_remove.Outcome.value_counts() / len(ds_OUT_remove.Outcome))[1],0))\n",
    "H=int(round((100. * ds_OUT_remove.Outcome.value_counts() / len(ds_OUT_remove.Outcome))[0],0))\n",
    "fig , ax = plt.subplots(figsize=(10,6))\n",
    "ax.barh([1], df_count.Outcome[1], height=0.7, color= colors[1])\n",
    "ax.barh([0], df_count.Outcome[0], height=0.7, color= colors[0])\n",
    "\n",
    "fig.patch.set_facecolor(colors[4])\n",
    "ax.set_facecolor(colors[4])\n",
    "\n",
    "ax.axes.get_xaxis().set_visible(True)\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.text(-80,-0.1, 'Negative',{'font': 'Rockwell','weight':'bold','Size': '16','style':'normal', 'color':colors[0]})\n",
    "plt.text(420,-0.1, ''+str(H)+' %',{'font':'Rockwell','weight':'bold' ,'size':'16','color':colors[0]})\n",
    "plt.text(-70,1, 'Positive', {'font': 'Rockwell','weight':'bold','Size': '16','style':'normal', 'color':colors[1]})\n",
    "plt.text(200,1, ''+str(D)+'%',{'font':'Rockwell', 'weight':'bold','size':'16','color':colors[1]})\n",
    "\n",
    "plt.text(80,1.77, 'Percentage bar of Outcome' ,{'font': 'Rockwell', 'Size': '25','weight':'bold', 'color':colors[3]})\n",
    "plt.text(450,1.6, 'Positive', {'font': 'Rockwell','weight':'bold','Size': '16','weight':'bold','style':'normal', 'color':colors[1]})\n",
    "plt.text(500,1.6, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\n",
    "plt.text(510,1.6, 'Negative', {'font': 'Rockwell','weight':'bold', 'Size': '16','style':'normal', 'weight':'bold','color':colors[0]})\n",
    "plt.text(-50,1.5, 'It is an unbalanced distribution, and visibly seen that  '+str(D)+ '  in 100  persons are diabetic.', \n",
    "        {'font':'Rockwell','weight':'bold', 'size':'14','color': colors[0]})\n",
    "plt.show()\n",
    "#wandb.log({\"Outcome-Precentage\": wandb.Image(fig)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696385a",
   "metadata": {},
   "source": [
    "    - Target variable / Dependent variable is discrete and categorical in nature.\n",
    "    \n",
    "    - Target (Outcome) classes are 1 and 0;where 1 being diabetic (Positive) and 0 being None (Negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70207de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 15))\n",
    "i=0\n",
    "for col in ds_OUT_remove.drop('Outcome', axis=1).columns:\n",
    "    i+=1\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.hist(ds_OUT_remove[col])\n",
    "    plt.subplots_adjust(hspace = .4)\n",
    "    plt.title(f'Distribuation of {col}', fontsize=15)\n",
    "    plt.xlabel('index', fontsize=12)\n",
    "    plt.ylabel(f'{col}', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f080b49",
   "metadata": {},
   "source": [
    "### [3 : 3 : 2] Bi-Variate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4641b",
   "metadata": {},
   "source": [
    "##### Scatter plot \n",
    "\n",
    "While doing bi-variate analysis between two continuous variables, we should look at scatter plot. It is a nifty way to find out the relationship between two variables. The pattern of scatter plot indicates the relationship between variables. The relationship can be linear or non-linear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4769ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 15))\n",
    "i=0\n",
    "for col in ds.drop('Outcome', axis=1).columns:\n",
    "    i+=1\n",
    "    plt.subplot(3,3,i)\n",
    "    sns.scatterplot(x=ds.index, y=ds[col], hue=ds['Outcome'])\n",
    "    plt.subplots_adjust(hspace = .4)\n",
    "    plt.title(f'Distribuation of {col}', fontsize=15)\n",
    "    plt.xlabel('index', fontsize=12)\n",
    "    plt.ylabel(f'{col}', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160cfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def scatt(col1, col2):\n",
    "    plt.subplots(figsize=(10, 8))\n",
    "    pd.set_option(\"plotting.backend\", \"plotly\")\n",
    "    df=ds_OUT_remove.copy()\n",
    "    plt.title(f'{col1} vs {col2}'+' (r = {0:0.2f})'.format(pearsonr(df[col1],df[col2])[0]))\n",
    "    df.Outcome = df.Outcome.replace({0:'Negative',1:'Positive'})\n",
    "    sns.scatterplot(x=col1,y=col2,data = df, hue='Outcome')\n",
    "    plt.show()\n",
    "    \n",
    "scatt(\"Glucose\", 'BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scat(col1,col2):\n",
    "    sns.FacetGrid(ds_OUT_remove, hue='Outcome', size=5).map(plt.scatter,col1,col2).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "scat('Age','Glucose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98ec16",
   "metadata": {},
   "source": [
    "##### Correlation coffecient\n",
    "\n",
    "Scatter plot shows the relationship between two variable but does not indicates the strength of relationship amongst them. To find the strength of the relationship, we use Correlation. Correlation varies between -1 and +1.\n",
    "\n",
    "-1: perfect negative linear correlation\n",
    "\n",
    "+1:perfect positive linear correlation and \n",
    "\n",
    " 0: No correlation\n",
    " \n",
    "Correlation can be derived using following formula:\n",
    "\n",
    "Correlation = Covariance(X,Y) / SQRT( Var(X)* Var(Y))\n",
    "\n",
    "It returns Pearson Correlation value to identify the relationship between two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds.columns[1:]].corr()['Outcome'][:].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fe576",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = ds_OUT_remove.corr()\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "sns.heatmap(corr,vmax=1.0, center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": .5}, annot = True,annot_kws={'fontsize':14})\n",
    "#wandb.log({\"Correlation Mx\": wandb.Image(f)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660d336",
   "metadata": {},
   "source": [
    "Insights :\n",
    "\n",
    "   - From the above heatmap, we can observe that all the features are weakly correlated .\n",
    "   \n",
    "   - we can infer that “Insulin” has the best positive correlation with “Outcome” but not strong\n",
    "\n",
    "   - “BloodPressure” and “DPF” has the lowest correlation with “Outcome”.\n",
    "\n",
    "   - \"Age\" has the highest positive correlation with \"Pregnancies\" but not strong  \n",
    "   \n",
    "   - \"BMI\" has the highest positive correlation in the dataset with \"SkinThikness\" but not strong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da0bca",
   "metadata": {},
   "source": [
    "### [3 : 3 : 3]  Multi-Variate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 120)\n",
    "sns.pairplot(ds_OUT_remove,hue = 'Outcome',palette = colors[2:4])\n",
    "plt.legend(['Negative','Positive'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 110,figsize= (8,4))\n",
    "mask = np.triu(np.ones_like(ds_OUT_remove.corr(),dtype = bool))\n",
    "sns.heatmap(ds_OUT_remove.corr(),mask = mask, fmt = \".2f\",annot=True,lw=2,cmap = colors)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6791b0b",
   "metadata": {},
   "source": [
    "## [3 : 4] Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3d4db",
   "metadata": {},
   "source": [
    "We perform feature engineering once you have completed the first 5 steps in data exploration – Variable Identification, Univariate, Bivariate Analysis, Missing Values Imputation and Outliers Treatment. Feature engineering itself can be divided in 2 steps:\n",
    "\n",
    "1- Variable transformation.\n",
    "\n",
    "2- Variable creation / extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1743b9a",
   "metadata": {},
   "source": [
    "### [3 : 4 : 1] Variable Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27103963",
   "metadata": {},
   "source": [
    "So now we have completed both missing values and outliers handling. Next, we are going to explore Q-Q plots and distplots to check whether we need to apply any transformations to the dataset !\n",
    "\n",
    "By applying a number of transformations to variables, and mapping their skewed distribution to a normal distribution, we can increase the performance of our models.\n",
    "\n",
    "First, we have to see if our variables follow a normal distribution or not. We can estimate normality with Diatplot and Q-Q plot :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af465045",
   "metadata": {},
   "source": [
    "#### [3 : 4 : 1 : 1] Normality of dataset\n",
    "\n",
    "kurtosis and skew are two common terms you might run into when describing normality. We can formally calculate the skew and kurtosis of the distribution using SciPy’s stats\n",
    "\n",
    "    Skewness\n",
    "\n",
    "It is the degree of distortion from the symmetrical bell curve or the normal distribution. It measures the lack of symmetry in data distribution. It differentiates extreme values in one versus the other tail. A symmetrical distribution will have a skewness of 0.\n",
    "\n",
    "    Kurtosis\n",
    "\n",
    "Kurtosis is all about the tails of the distribution — not the peakedness or flatness. It is used to describe the extreme values in one versus the other tail. It is actually the measure of outliers present in the distribution :\n",
    "\n",
    "    (1) Kurtosis (Mesokurtic) :\n",
    "\n",
    "This distribution has kurtosis statistic similar to that of the normal distribution. It means that the extreme values of the distribution are similar to that of a normal distribution characteristic. This definition is used so that the standard normal distribution has a kurtosis of three.\n",
    "\n",
    "    (2) Kurtosis (Leptokurtic (Kurtosis > 3)) :\n",
    "\n",
    "Distribution is longer, tails are fatter. Peak is higher and sharper than Mesokurtic, which means that data are heavy-tailed or profusion of outliers .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4dbfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def skew_kurtosis(df,col):\n",
    "    #Calculating Skew and Kurtosis \n",
    "    kurtosis = round((stats.kurtosis(df[col])), ndigits=3)\n",
    "    skew = round((stats.skew(df[col])), ndigits=3)\n",
    "    #Interpreting Skew \n",
    "    if -0.5 < skew < 0.5:\n",
    "        print (f'(1) The skew is {skew},and means the distribution is approx. symmetric. \\n')\n",
    "    elif  -0.5 < skew < -1.0 or 0.5 < skew < 1.0:\n",
    "        print (f'(1) The skew is {skew}, and means the distribution is moderately skewed. \\n')\n",
    "    else:\n",
    "        print (f'(1) The skew is {skew}, and means the distribution is highly skewed. \\n')\n",
    "\n",
    "    #Interpreting Kurtosis\n",
    "    if  -0.5 < kurtosis < 0.5:\n",
    "        print (f'(2) The kurtosis is {kurtosis}, and means the distribution is approximately normal sometimes called mesokurtic distributions.')\n",
    "    elif kurtosis <= -0.5: \n",
    "        print (f'(2) The kurtosis is {kurtosis}, and means the distribution is light-tailed (negative) sometimes called a platykurtic distributions.')\n",
    "    elif kurtosis >= 0.5:\n",
    "        print (f'(2) The kurtosis is {kurtosis}, and means the distribution is heavy-tailed (positive) sometimes called a leptokurtic distribution.')\n",
    "\n",
    "def normality(df):\n",
    "    j=1\n",
    "    color = ['#454140','#c1502e','#a79e84','#7a3b2e','#454140','#c1502e','#a79e84','#7a3b2e','#454140','#c1502e','#a79e84']\n",
    "    df_name =[x for x in globals() if globals()[x] is df][0]\n",
    "    print(colored(f\"\\n\\n =====================| The Normality test of {df_name}  dataset  |============================= \\n\\n\",'blue'))\n",
    "    for col in df.drop('Outcome', axis=1).columns: \n",
    "        fig = plt.figure(figsize=(12,35))\n",
    "        plt.subplot(8,1,j)\n",
    "        print(f\"\\n\\n###### Skew and Kurtosis of {col} ######\\n\")\n",
    "\n",
    "        sns.histplot(df[col], bins = 30, kde = True, color=color[j])\n",
    "        j += 1\n",
    "        plt.show()\n",
    "        print(str(skew_kurtosis(df,col)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384137aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normality(ds_OUT_remove)\n",
    "normality(ds_OUT_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb1c77",
   "metadata": {},
   "source": [
    "#### [ 3 : 4 : 1 : 2 ] Get Q-Q for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ca6b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_dist_probplot(df): \n",
    "    fig=plt.figure(figsize=(15, 40))\n",
    "    i=1\n",
    "    plt.subplots_adjust(hspace = .6)  \n",
    "    sns.set_theme()\n",
    "    sns.set_color_codes()\n",
    "    for col in df.drop('Outcome', axis=1).columns:\n",
    "        plt.subplot(8, 2, i)\n",
    "        ax = sns.distplot(df[col], fit=stats.norm)\n",
    "        #ax = sns.histplot(df[col], kde=True, stat='density', label='samples')\n",
    "        ax.set_title(f'DistPlot of {col}')\n",
    "        ax.set_xlabel('Value Bin')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        #=========================================\n",
    "        ax1 = plt.subplot(8, 2, i+1)\n",
    "        plt.title(f\"{col}\")\n",
    "        res = stats.probplot(df[col], plot=plt)\n",
    "        ax1.get_lines()[0].set_marker('p')\n",
    "        ax1.get_lines()[0].set_markerfacecolor('#454140')\n",
    "        ax1.get_lines()[0].set_markersize(5.0)\n",
    "        #ax1.get_lines()[1].set_linewidth(5.0)\n",
    "\n",
    "        i+=2\n",
    "        \n",
    "get_dist_probplot(ds_OUT_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc52c8a",
   "metadata": {},
   "source": [
    "By looking at these plots we can see some features need to be transformed. The reason is the distribution is not symmetrical. So the skewness is present. To eliminate this issue we can perform transformations like logarithm transformation, square root transformation, or exponential transformation.\n",
    "\n",
    "We know that logarithm of 0 undefined so we have to use square root transformation. The below screenshot shows applying the transformation, and plotting again Q-Q plot and distribuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a0375",
   "metadata": {},
   "source": [
    "#### [ 3 : 4 : 1 : 3 ] Detect for the best (Power or Quantile transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns=columns_with_missing_values.tolist()\n",
    "def check_transformers(df):\n",
    "    pt = PowerTransformer()\n",
    "    qt = QuantileTransformer(n_quantiles=500, output_distribution='normal')\n",
    "    fig = plt.figure(figsize=(20,30))\n",
    "    j = 1\n",
    "    for i in df.drop('Outcome',axis=1).columns:\n",
    "        array = np.array(ds[i]).reshape(-1, 1)\n",
    "        y = pt.fit_transform(array)\n",
    "        x = qt.fit_transform(array)\n",
    "        plt.subplot(8,3,j)\n",
    "        sns.histplot(array, bins = 50, kde = True)\n",
    "        plt.title(f\"Original Distribution for {i}\")\n",
    "        plt.subplot(8,3,j+1)\n",
    "        sns.histplot(x, bins = 50, kde = True)\n",
    "        plt.title(f\"Quantile Transform for {i}\")\n",
    "        plt.subplot(8,3,j+2)\n",
    "        sns.histplot(y, bins = 50, kde = True)\n",
    "        plt.title(f\"Power Transform for {i}\")\n",
    "        j += 3\n",
    "check_transformers(ds_OUT_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ad52f",
   "metadata": {},
   "source": [
    "It can be seen that QuantileTransformer has performed better than PowerTransformer in terms of converting the skewed distribution into normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70857313",
   "metadata": {},
   "source": [
    "#### [ 3 : 4 : 1 : 4 ] Show the most common transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b97d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the best transformer according to every variable individually\n",
    "Trans=ds_OUT_remove.copy()\n",
    "fig=plt.figure(figsize=(20, 35))\n",
    "cols = Trans.drop('Outcome', axis =1).columns.tolist()\n",
    "qq=[np.sqrt, np.log, lambda x: x**(3), 'yeo-johnson','Quantile_Trans']\n",
    "qq_lst=['Square_Root_Trans', 'Logarithmic_Trans', 'Exponential_Trans', 'Yeo_Johnson_Trans', 'Quantile_Trans']\n",
    "dfs = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DPF', 'Age']  \n",
    "for item in dfs:\n",
    "     exec('{} = pd.DataFrame()'.format(item))    \n",
    "\n",
    "dfs = [Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DPF, Age] \n",
    "# create the function transformer object with logarithm transformation\n",
    "for i in range(len(qq)):\n",
    "    if i <= 2:\n",
    "        tran = FunctionTransformer(qq[i], validate=True)\n",
    "    elif i == 3:\n",
    "        tran = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "        tran.fit(Trans[cols])\n",
    "    else:\n",
    "        tran = QuantileTransformer(n_quantiles=500, output_distribution='normal')\n",
    "        tran.fit_transform(Trans[cols])\n",
    "    # apply the transformation to your data\n",
    "    arr = tran.transform(Trans[cols])\n",
    "    data = pd.DataFrame(data=arr[0:,0:],\n",
    "                        index=[i for i in range(arr.shape[0])],\n",
    "                        columns=cols)\n",
    "    Pregnancies.insert(i,f\"{qq_lst[i]}\", data['Pregnancies'].tolist(), True)\n",
    "    Glucose.insert(i,f\"{qq_lst[i]}\", data['Glucose'].tolist(), True)\n",
    "    BloodPressure.insert(i,f\"{qq_lst[i]}\", data['BloodPressure'].tolist(), True)\n",
    "    SkinThickness.insert(i,f\"{qq_lst[i]}\", data['SkinThickness'].tolist(), True)\n",
    "    Insulin.insert(i,f\"{qq_lst[i]}\", data['Insulin'].tolist(), True)\n",
    "    BMI.insert(i,f\"{qq_lst[i]}\", data['BMI'].tolist(), True)\n",
    "    DPF.insert(i,f\"{qq_lst[i]}\", data['DPF'].tolist(), True)\n",
    "    Age.insert(i,f\"{qq_lst[i]}\", data['Age'].tolist(), True)\n",
    "\n",
    "# Get Q-Qplot\n",
    "i=1\n",
    "for df in dfs:\n",
    "    df_name =[x for x in globals() if globals()[x] is df][0]\n",
    "    for col in df.columns:\n",
    "        plt.subplot(9, 5, i)\n",
    "        stats.probplot(df[col], dist=\"norm\", plot=plt)\n",
    "        plt.subplots_adjust(hspace = .6)\n",
    "        plt.title(f\"{col}\")  \n",
    "        i+=1\n",
    "    plt.text(-43, 1, f\"{df_name}\",color='white', fontsize=15, weight='bold', ha=\"left\", va=\"top\", \n",
    "             bbox=dict(boxstyle=\"rarrow\",\n",
    "                   ec=\"#008080\",\n",
    "                   fc=\"#1f77b4\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00f173",
   "metadata": {},
   "source": [
    "By looking at the dist and Q-Q plots for all variables we find that the quantile transformer is the best and accped for most variables (Glucose, DiabetesPedigreeFunction, BMI), while Log transformer is the best solution for Age variable !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b6512",
   "metadata": {},
   "source": [
    "#### [ 3 : 4 : 1 :  5 ] Applying transformation (Quantile and Log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd91051",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform only Glucose, DPF, BMI and Age columns which looking better with transformation\n",
    "def transform_cols(data, probplot=False):\n",
    "    df=data.copy()\n",
    "    cols = ['Glucose','DPF', 'BMI']\n",
    "    qt = QuantileTransformer(n_quantiles=500, output_distribution='normal')\n",
    "    transformed_data = qt.fit_transform(df[cols])\n",
    "    df[cols]= transformed_data\n",
    "    df['Age'] = np.log(df['Age'])\n",
    "    if probplot:\n",
    "        get_dist_probplot(df)\n",
    "    return df\n",
    "\n",
    "Trans_OUT_remove=transform_cols(ds_OUT_remove)\n",
    "#Trans_OUT_replace=transform_cols(ds_OUT_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad77463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers after transformation\n",
    "detect_outliers_iqr(Trans_OUT_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00feecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outliers after applying transformation\n",
    "for col in Trans_OUT_remove.drop('Outcome', axis=1).columns:\n",
    "    Trans_OUT_remove = remove_outlrs(Trans_OUT_remove,col,'iqr')\n",
    "#for col in Trans_OUT_replace.drop('Outcome', axis=1).columns:\n",
    "    #Trans_OUT_replace = remove_outlrs(Trans_OUT_replace,col,'iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b558f0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_dist_probplot(Trans_OUT_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bafd01",
   "metadata": {},
   "source": [
    "### [3 : 4 : 2]   Variable Creation / Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1d1e8",
   "metadata": {},
   "source": [
    "Variable creation is a process to generate a new variables / features based on existing variable(s), examples :\n",
    "\n",
    "1- Creation derived variables\n",
    "\n",
    "2- Creation dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472731ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def cat_pie(data,col,col_cat):\n",
    "    fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "    df =pd.DataFrame(data.groupby(['Outcome'])[col_cat].value_counts().reset_index(name='count'))\n",
    "    df.sort_values(['Outcome', 'level_1'], ascending=[True, True], inplace=True)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "    fig.add_trace(go.Pie(labels=df[df['Outcome']==1]['level_1'].tolist(),\n",
    "                     values=df[df['Outcome']==1]['count'].tolist(), name=\"Diabetic\"),\n",
    "              1, 1)\n",
    "    fig.add_trace(go.Pie(labels=df[df['Outcome']==0]['level_1'].tolist(), \n",
    "                     values=df[df['Outcome']==0]['count'].tolist(), name=\"Healthy\"),\n",
    "              1, 2)\n",
    "    fig.update_traces(hole=.4, hoverinfo=\"label+percent+name+value\",textfont={'color': 'white', 'size': 12},\n",
    "                 marker=dict(colors=colors,line=dict(color='white', width=3)),outsidetextfont={'color':'Black'})\n",
    "\n",
    "    fig.update_layout(height = 600,\n",
    "                      width = 800,\n",
    "    title_text=\"Groups of \"+str(col)+\"  by Outcome\",\n",
    "    annotations=[dict(text='Diabetic', x=0.16, y=0.5, font_size=15, showarrow=False),\n",
    "                 dict(text='Healthy', x=0.84, y=0.5, font_size=15, showarrow=False)])\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "def cat_bar(df,col,cat_col):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    df=df[cat_col].value_counts().reset_index()\n",
    "    ax.barh(df['index'], df[cat_col], color=colors)\n",
    "    dx = df[cat_col].max() / 200\n",
    "    for i, (value, name) in enumerate(zip(df[cat_col], df['index'])):\n",
    "        ax.text(value+dx, i+.05,     name,           size=12, weight=500, ha='left',color='#696969', va='bottom')\n",
    "        ax.text(value+dx, i-.1,     value,  size=13, ha='left',weight='bold',color='black',  va='top')\n",
    "  \n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.tick_params(axis='x', colors='red', labelsize=12)\n",
    "    ax.set_yticks([])\n",
    "    ax.margins(0, 0.01)\n",
    "    ax.grid(which='major', axis='x', linestyle='-')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.text(0, 1.20, 'Observations per '+str(col)+' groups during full dataset',\n",
    "            transform=ax.transAxes, size=20, weight=200, ha='center')\n",
    "    plt.box(False)\n",
    "\n",
    "def boxplot_cat(df,col_cat):\n",
    "    data=df.copy()\n",
    "    data.Outcome.replace([0, 1], ['Negative', 'Positive'], inplace=True)\n",
    "    sns.set(rc={'figure.figsize':(12.7,6.27)})\n",
    "    sns.boxplot(x=\"Age\", y=col_cat, hue=\"Outcome\", data=data, palette=colors[1:3],showmeans=True,\n",
    "            meanprops={\"marker\":\"s\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"blue\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b990405",
   "metadata": {},
   "source": [
    "#### [3 : 4 : 2 : 1]  Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset that after removing outliers\n",
    "ds_CAT=ds_OUT_remove.copy()\n",
    "# Copy the dataset that before removing outlies\n",
    "#ds_CAT=ds.copy()\n",
    "# Create list for labels and Bins to \n",
    "cats = []\n",
    "# Loop for creating features \n",
    "def create_feature(df):\n",
    "    for col, labels, bins, new_col in cats:\n",
    "        bins.append(df[col].max())\n",
    "        category = pd.cut(df[col],bins=bins,labels=labels).astype('category')\n",
    "        df.insert(df.columns.get_loc(col),new_col,category)\n",
    "        bins.pop()\n",
    "    return df\n",
    "# New features derived only from BMI, Insulin, Glucose, BloodPressure and Age\n",
    "cats.append(('BMI', ['Underweight','Healthy','Overweight','Obesity'] ,[0,18.5,25,30],'BMI_group'))\n",
    "cats.append(('Insulin', ['Normal', 'Abnormal'], [16.0,166.0], 'Insulin_group'))\n",
    "cats.append(('Glucose', ['Normal', 'Abnormal'], [0,140.0], 'Glucose_group'))\n",
    "cats.append(('BloodPressure', ['Normal','AtRisk','HighBP'], [0,80,89], 'BP_group'))\n",
    "cats.append(('Age', ['Adult','MiddleAdult','OldAdult'], [20,40,60], 'Age_group'))\n",
    "\n",
    "# Apply and save the new datasets   \n",
    "#ds_CAT = create_feature(ds_CAT)\n",
    "ds_CAT = create_feature(ds_CAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f5e7b",
   "metadata": {},
   "source": [
    "###### BMI Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_CAT.BMI.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed524de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==========| the value count for BMI_group |============\\n\\n\",ds_CAT['BMI_group'].value_counts().to_dict(), \"\\n\")\n",
    "print(\"\\n==========|The precentage of BMI categories by the mean of Outcome :  |============\\n\\n\",round(ds_CAT.groupby('BMI_group')['Outcome'].mean(),2).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pie(ds_CAT,'BMI','BMI_group')\n",
    "cat_bar(ds_CAT,'BMI','BMI_group')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf730e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_cat(ds_CAT,'BMI_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686184f",
   "metadata": {},
   "source": [
    "Underweight category is Zero in Diabetic Casese, it is better to be removed !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('The dataset shape BEFORE deleting BMI Underweight rows :\\n',ds.shape)\n",
    "#ds = ds[ds.BMI_group != 'Underweight']\n",
    "#print('The dataset shape AFTER deleting BMI Underweight rows :\\n',ds.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e3832",
   "metadata": {},
   "source": [
    "##### Insulin Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3583a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_CAT.Insulin.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d0ba7",
   "metadata": {},
   "source": [
    "Insulin Normal Range If insulin level (2-Hour serum insulin (mu U/ml)) is >= 16 and <= 166, else it is considered as Abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==========| the value count for Insulin_group |============\\n\\n\",ds_CAT['Insulin_group'].value_counts().to_dict(), \"\\n\")\n",
    "print(\"\\n==========|The precentage of Insulin categories by the mean of Outcome :  |============\\n\\n\",ds_CAT.groupby('Insulin_group')['Outcome'].mean().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd003e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pie(ds_CAT,'Insulin','Insulin_group')\n",
    "cat_bar(ds_CAT,'Insulin','Insulin_group')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3abe23c",
   "metadata": {},
   "source": [
    "It seems from the above barplot that around 500 patients have Normal Insulin Levels where more than 250 patients have Abnormal Insulin Levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_cat(ds_CAT,'Insulin_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930c7e37",
   "metadata": {},
   "source": [
    "##### Glucose Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f106d7b",
   "metadata": {},
   "source": [
    "a blood sugar level of 140 mg/dL or lower is considered normal, 140 to 199 mg/dL indicates you have prediabetes, and 200 mg/dL or higher indicates you have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13893f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==========| the value count for Glucose_group |============\\n\\n\",ds_CAT['Glucose_group'].value_counts().to_dict(), \"\\n\")\n",
    "print(\"\\n==========|The precentage of Glucose categories by the mean of Outcome :  |============\\n\\n\",ds_CAT.groupby('Glucose_group')['Outcome'].mean().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_bar(ds_CAT,'Glucose','Glucose_group')\n",
    "cat_pie(ds_CAT,'Glucose','Glucose_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_cat(ds_CAT,'Glucose_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5426be9",
   "metadata": {},
   "source": [
    "##### BloodPressure Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49467b97",
   "metadata": {},
   "source": [
    "diastolic: less than 80 mm Hg (Normal)\n",
    "diastolic: 80–89 mm Hg (At_Risk)\n",
    "diastolic: 90 mm Hg or higher (High_BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa209ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_CAT.BloodPressure.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e35630",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==========| the value count for BP_group |============\\n\\n\",ds_CAT['BP_group'].value_counts().to_dict(), \"\\n\")\n",
    "print(\"\\n==========|The precentage of BloodPressure categories by the mean of Outcome :  |============\\n\\n\",ds_CAT.groupby('BP_group')['Outcome'].mean().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154eb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_bar(ds_CAT,'BloodPressure','BP_group')\n",
    "cat_pie(ds_CAT,'BloodPressure','BP_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_cat(ds_CAT,'BP_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1522d",
   "metadata": {},
   "source": [
    "##### Age Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_CAT.Age.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==========| the value count for Age_group |============\\n\\n\",ds_CAT['Age_group'].value_counts().to_dict(), \"\\n\")\n",
    "print(\"\\n==========|The precentage of Age categories by the mean of Outcome :  |============\\n\\n\",ds_CAT.groupby('Age_group')['Outcome'].mean().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffa227",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_bar(ds_CAT,'Age','Age_group')\n",
    "cat_pie(ds_CAT,'Age','Age_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c121d",
   "metadata": {},
   "source": [
    "#### [3 : 4 : 2 : 2]   Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380261ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform numeric features \n",
    "Trans_CAT=ds_CAT.copy()\n",
    "cols = ['Glucose','DPF', 'BMI']\n",
    "qt = QuantileTransformer(n_quantiles=500, output_distribution='normal')\n",
    "transformed_data = qt.fit_transform(Trans_CAT[cols])\n",
    "Trans_CAT[cols]= transformed_data\n",
    "Trans_CAT['Age'] = np.log(Trans_CAT['Age'])\n",
    "\n",
    "for col in ds.drop('Outcome', axis=1).columns:\n",
    "    Trans_CAT = remove_outlrs(Trans_CAT,col,'iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f20bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get thw dummy variables\n",
    "def get_dummies(df):\n",
    "    cat_var = df.select_dtypes(include=['category'])\n",
    "    #for var in cat_var:    \n",
    "        #print(f\"\\n==========| the value count for {var} |============\\n\\n\",df[var].value_counts().to_dict(), \"\\n\")\n",
    "    dums =df.copy()\n",
    "    for i in cat_var:\n",
    "        dums = pd.concat([dums,pd.get_dummies(dums[i],prefix=i)],axis=1)\n",
    "        dums.drop(i, axis=1, inplace=True)\n",
    "    return dums\n",
    "Trans_CAT = get_dummies(Trans_CAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07f525",
   "metadata": {},
   "source": [
    "# {4} MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388c961",
   "metadata": {},
   "source": [
    "#### Modeling of dataset with main Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477784bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.colheader_justify', 'center')\n",
    "def split_fit(df):\n",
    "    X = df.drop(['Outcome'], axis=1)\n",
    "    y = df['Outcome']\n",
    "    ds_unscaled=X.values\n",
    "    ds_minmax = preprocessing.StandardScaler().fit_transform(ds_unscaled)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(ds_minmax, y, test_size=0.2,random_state=42)\n",
    "    \n",
    "    #SMOTE\n",
    "    #sm = SMOTE(random_state=42)\n",
    "    #X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    classifiers = [\n",
    "    LGBMClassifier(),\n",
    "    KNeighborsClassifier(10),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(max_iter = 100),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    ExtraTreesClassifier(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(random_state=0, solver='liblinear')]\n",
    "\n",
    "    # Logging for Visual Comparison\n",
    "    cols=['Model','Train_Accuracy','Test_Accuracy','Log_Loss']\n",
    "    dt = pd.DataFrame(columns=cols)\n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        name = clf.__class__.__name__\n",
    "    \n",
    "        print(\"=\"*30)\n",
    "        print(name)\n",
    "    \n",
    "        print('****| Results |****')\n",
    "        train_accuracy= accuracy_score(y_train, clf.predict(X_train))\n",
    "        test_predictions = clf.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "        print(\"Train Accuracy: {:.1%}\".format(train_accuracy))\n",
    "        print(\"Test Accuracy: {:.1%}\".format(test_accuracy))\n",
    "    \n",
    "        proba_predictions = clf.predict_proba(X_test)\n",
    "        lgls = log_loss(y_test, proba_predictions)\n",
    "        print(\"Log Loss: {:.2}\".format(lgls))\n",
    "    \n",
    "        print(classification_report(y_test, test_predictions)) \n",
    "\n",
    "        entry = pd.DataFrame([[name,train_accuracy*100, test_accuracy*100, lgls]], columns=cols)\n",
    "        dt = dt.append(entry)\n",
    "    print(\"=\"*30)\n",
    "    dt.sort_values(['Test_Accuracy', 'Log_Loss'], ascending=[False, True], inplace=True)\n",
    "    dt[['Train_Accuracy','Test_Accuracy']]=dt[['Train_Accuracy','Test_Accuracy']].applymap(lambda x: str(int(x)) + ' %' if abs(x - int(x)) < 1e-6 else str(\"{0:.1f} %\".format(x)))\n",
    "    dt.index = np.arange(1, len(dt) + 1)\n",
    "    dfmg.export(dt,\"results.png\")\n",
    "    display(dt)\n",
    "\n",
    "def get_max(y,p):\n",
    "    labels = [\"Negative\", \"Positive\"]\n",
    "    cm  = confusion_matrix(y, p)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, hide_ticks=True, cmap='Reds')\n",
    "    plt.xticks(range(2), labels, fontsize=14)\n",
    "    plt.yticks(range(2), labels, fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "def get_params(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, test_predictions)\n",
    "    print('\\n\\n---------| The accuracy |----------- \\n')\n",
    "    print(\"Train Accuracy: {:.2%}\".format(train_acc))\n",
    "    print(\"Test Accuracy: {:.2%}\".format(test_acc))\n",
    "    print('\\n\\n---------| The parameters |----------- \\n')\n",
    "    display(model.get_params())\n",
    "    get_max(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07602b1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit models and evaluate loss and Accuracy\n",
    "split_fit(Trans_OUT_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df53e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DATASET\n",
    "featurs = Trans_OUT_remove.drop(columns=\"Outcome\")\n",
    "target = Trans_OUT_remove['Outcome']\n",
    "ds_unscaled=featurs.values\n",
    "ds_minmax = preprocessing.StandardScaler().fit_transform(ds_unscaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds_minmax, target, test_size=0.2,random_state=42)\n",
    "# SMOTE\n",
    "#smt = SMOTE(random_state=2)\n",
    "#X_train, y_train = smt.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d22f3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGBClassifier Model\n",
    "error_rate = []\n",
    "for i in range(1,10):\n",
    "    knn = XGBClassifier(max_depth=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "k=error_rate.index(min(error_rate))+1\n",
    "print(\"Minimum error with XGBClassifier: \",min(error_rate),\"at max_depth =\",k)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(range(1,10),error_rate,color='#a79e84', linestyle='dashed', \n",
    "         marker='o',markerfacecolor='#c1502e', markersize=12)\n",
    "plt.title('Error Rate vs. n-max-depth value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xticks(np.arange(1, 10, 1))\n",
    "plt.show()\n",
    "model = XGBClassifier(max_depth=k)\n",
    "get_params(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9deaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model\n",
    "error_rate = []\n",
    "for i in range(1,50):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "k=error_rate.index(min(error_rate))+1\n",
    "print(\"Minimum error with KNN model :\",min(error_rate),\"at n_neighbors =\",k)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=12)\n",
    "plt.title('Error Rate vs. n-neighbors value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xticks(np.arange(1, 50, 2))\n",
    "plt.show()\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "get_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier Model \n",
    "error_rate = []\n",
    "for i in [2,3]:\n",
    "    for j in range(1,15):\n",
    "        rfc = RandomForestClassifier(max_depth=j,min_samples_split=i)\n",
    "        rfc.fit(X_train,y_train)\n",
    "        pred_i = rfc.predict(X_test)\n",
    "        error_rate.append(np.mean(pred_i != y_test))\n",
    "er_1=error_rate[:14]\n",
    "er_2=error_rate[14:]\n",
    "k = error_rate.index(min(error_rate))+1\n",
    "if k >= 14 :\n",
    "    mss = 3\n",
    "else:\n",
    "    mss = 2\n",
    "print(\"Minimum error with RandomForestClassifier : \",min(error_rate),\"at min-sample-split =\",mss, \"and max-depth = \",k)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(range(1,15),er_1,color='red', linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.plot(range(1,15),er_2,color='blue', linestyle='dashed', \n",
    "         marker='o',markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate vs. min_samples_split vs. max_depth')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xticks(np.arange(1, 16, 1))\n",
    "plt.show()\n",
    "model = RandomForestClassifier(max_depth=k, min_samples_split=mss)\n",
    "get_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "get_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(random_state=0,solver=\"liblinear\").fit(X_train,y_train)\n",
    "logistic_regression_roc = roc_auc_score(y_train,logistic_regression.predict(X_train))\n",
    "\n",
    "fp,tp,trshld = roc_curve(y_train,logistic_regression.predict_proba(X_train)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fp,tp,label=\"Area Under Curve(AUC)\" %logistic_regression_roc)\n",
    "plt.plot([0,1],[0,1],\"r--\")\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic(ROC)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c632786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "#eval_metric = [\"auc\",\"error\"]\n",
    "#%time model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49333e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save XGB model\n",
    "#pickle.dump(model, open(\"XGBmodel_8F_96.pickle.dat\", \"wb\"))\n",
    "\n",
    "# Load XGB model\n",
    "#loaded_model = pickle.load(open(\"XGBmodel_8F_96.pickle.dat\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
